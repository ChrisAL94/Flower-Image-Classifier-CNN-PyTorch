{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import der notwendigen Bibliotheken\n",
    "\n",
    "Zunächst werden alle für den Code notwendigen Pakete importiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "\n",
    "import json\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laden der Daten\n",
    "\n",
    "Hier werden die Bilddaten mithilfe des Torchvisionpakets geladen. Der Datensatz ist in zwei Teile gegliedert: Training und Validierung. Für das Training werden Transformationen wie zufällige Skalierung, Zuschneiden und Spiegeln angewendet. Dies wird dem Netzwerk helfen, sich zu verallgemeinern und zu einer besseren Leistung führen. Es muss außerdem sichergestellt werden, dass die Eingangsdaten auf 224x224 Pixel skaliert werden, wie von dem später verwendeten Netzwerk gefordert.\n",
    "\n",
    "Das Validierungsset wird verwendet, um die Leistung des Modells anhand von Daten zu messen, die es noch nicht gesehen hat. Dazu benötiget man keine Skalierung oder Rotationstransformationen, aber die Größe der Bilder muss richtig zugeschnitten werden.\n",
    "\n",
    "Die von torchvision verfügbaren vortrainierten Netzwerke wurden auf den ImageNet-Datensatz geschult, wobei jeder Farbkanal separat normiert wurde. Für beide Sets müssen die Mittelwerte und Standardabweichungen der Bilder auf das normalisiert werden, was das Netzwerk erwartet. Für die Mittelwerte ist es [0.485, 0.456, 0.406] und für die Standardabweichungen[0.229, 0.224, 0.225]- berechnet aus den ImageNet-Bildern. Diese Werte verschieben jeden zu zentrierenden Farbkanal um 0 und reichen von -1 bis 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/Christian/Programming/Pytorch/Final Project/flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "nThreads = 4\n",
    "batch_size = 32\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation der Bilder \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        #transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Laden des Datensatzes\n",
    "\n",
    "data_dir = 'flower_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'valid']}\n",
    "\n",
    "# Definieren des dataloaders\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'valid']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
    "\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Mapping\n",
    "\n",
    "Hier wird eine Zuordnung von Kategorienbezeichnung zu Kategoriename geladen. Diese befindet sich in der Datei cat_to_name.json. Es ist ein JSON-Objekt, das mit dem json-Modul eingelesen werden kann. Dies enthält eine Zuordnung von Zahlen zu den tatsächlichen Namen der Pflanzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "classes = json.loads('{\"21\": \"fire lily\", \"3\": \"canterbury bells\", \"45\": \"bolero deep blue\", \"1\": \"pink primrose\", \"34\": \"mexican aster\", \"27\": \"prince of wales feathers\", \"7\": \"moon orchid\", \"16\": \"globe-flower\", \"25\": \"grape hyacinth\", \"26\": \"corn poppy\", \"79\": \"toad lily\", \"39\": \"siam tulip\", \"24\": \"red ginger\", \"67\": \"spring crocus\", \"35\": \"alpine sea holly\", \"32\": \"garden phlox\", \"10\": \"globe thistle\", \"6\": \"tiger lily\", \"93\": \"ball moss\", \"33\": \"love in the mist\", \"9\": \"monkshood\", \"102\": \"blackberry lily\", \"14\": \"spear thistle\", \"19\": \"balloon flower\", \"100\": \"blanket flower\", \"13\": \"king protea\", \"49\": \"oxeye daisy\", \"15\": \"yellow iris\", \"61\": \"cautleya spicata\", \"31\": \"carnation\", \"64\": \"silverbush\", \"68\": \"bearded iris\", \"63\": \"black-eyed susan\", \"69\": \"windflower\", \"62\": \"japanese anemone\", \"20\": \"giant white arum lily\", \"38\": \"great masterwort\", \"4\": \"sweet pea\", \"86\": \"tree mallow\", \"101\": \"trumpet creeper\", \"42\": \"daffodil\", \"22\": \"pincushion flower\", \"2\": \"hard-leaved pocket orchid\", \"54\": \"sunflower\", \"66\": \"osteospermum\", \"70\": \"tree poppy\", \"85\": \"desert-rose\", \"99\": \"bromelia\", \"87\": \"magnolia\", \"5\": \"english marigold\", \"92\": \"bee balm\", \"28\": \"stemless gentian\", \"97\": \"mallow\", \"57\": \"gaura\", \"40\": \"lenten rose\", \"47\": \"marigold\", \"59\": \"orange dahlia\", \"48\": \"buttercup\", \"55\": \"pelargonium\", \"36\": \"ruby-lipped cattleya\", \"91\": \"hippeastrum\", \"29\": \"artichoke\", \"71\": \"gazania\", \"90\": \"canna lily\", \"18\": \"peruvian lily\", \"98\": \"mexican petunia\", \"8\": \"bird of paradise\", \"30\": \"sweet william\", \"17\": \"purple coneflower\", \"52\": \"wild pansy\", \"84\": \"columbine\", \"12\": \"colts foot\", \"11\": \"snapdragon\", \"96\": \"camellia\", \"23\": \"fritillary\", \"50\": \"common dandelion\", \"44\": \"poinsettia\", \"53\": \"primula\", \"72\": \"azalea\", \"65\": \"californian poppy\", \"80\": \"anthurium\", \"76\": \"morning glory\", \"37\": \"cape flower\", \"56\": \"bishop of llandaff\", \"60\": \"pink-yellow dahlia\", \"82\": \"clematis\", \"58\": \"geranium\", \"75\": \"thorn apple\", \"41\": \"barbeton daisy\", \"95\": \"bougainvillea\", \"43\": \"sword lily\", \"83\": \"hibiscus\", \"78\": \"lotus lotus\", \"88\": \"cyclamen\", \"94\": \"foxglove\", \"81\": \"frangipani\", \"74\": \"rose\", \"89\": \"watercress\", \"73\": \"water lily\", \"46\": \"wallflower\", \"77\": \"passion flower\", \"51\": \"petunia\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufbau und Schulung des Klassifikators\n",
    "\n",
    "Nach der Aufbereitung des Datensatzen kann ein Klassifikator aufgebaut werden. Hier wird als Basis das vortrainierte ResNet18 Modell verwenden. Darauf hin wird eine Feed-Forward-Klassifikator codiert und Trainiert..\n",
    "\n",
    "1. Laden des vortrainierten ResNet18 Netzwerkes.\n",
    "2. Definition eines neuen, untrainierten Feed-Forward-Netzwerks als Klassifizierer unter Verwendung von der ReLU-Aktivierungsfunktion.\n",
    "3. Trainieren der Klassifikatorebenen mittels Backpropagation über das vortrainierte Netzwerk.\n",
    "4. Dokumentation des Verlusts und der Genauigkeit des Validierungssatzes, um die besten Hyperparameter zu ermitteln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# laden des resnet-152 pre-trained network Modells\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Festsetzen der Paramater, damit die Gewichtungen nicht mehr veändert werden (backpropagation)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition eines neuen, untrainierten Feed-Forward-Netzwerks als Klassifizierer unter Verwendung von ReLU-Aktivierungen und Dropout.\n",
    "from collections import OrderedDict\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(512, 256)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(256, 102)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "\n",
    "\n",
    "\n",
    "# Austausch des vortrainierten Modellklassifikators durch den eigenen Klassifikator\n",
    "model.fc = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Jede Epoche hat eine Trainings- und Validierungsphase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Modell auf Trainingsmodus setzen\n",
    "            else:\n",
    "                model.eval()   # Modell auf Validiierungsmodus setzen\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iteration über die Daten.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Nullsetzen der Parametergradienten\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward: Speicher des Verlaufs im Trainingsmodus\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward: Optimierung im Trainingsmodus\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "          # Verrechnung \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Speichern des best-trainierten Modells\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid accuracy: {:4f}'.format(best_acc))\n",
    "\n",
    "    # Laden der Gewichtungen aus dem best-trainierten Modell\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 4.3230 Acc: 0.0885\n",
      "valid Loss: 3.8636 Acc: 0.2384\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 3.6296 Acc: 0.2730\n",
      "valid Loss: 3.0310 Acc: 0.3973\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 2.9556 Acc: 0.4167\n",
      "valid Loss: 2.3688 Acc: 0.5428\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 2.4325 Acc: 0.5252\n",
      "valid Loss: 1.8570 Acc: 0.6455\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 2.1847 Acc: 0.5784\n",
      "valid Loss: 1.8011 Acc: 0.6638\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 2.1415 Acc: 0.6021\n",
      "valid Loss: 1.7565 Acc: 0.6834\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 2.0977 Acc: 0.6056\n",
      "valid Loss: 1.7339 Acc: 0.6736\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 2.0669 Acc: 0.6175\n",
      "valid Loss: 1.7042 Acc: 0.6968\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 2.0308 Acc: 0.6226\n",
      "valid Loss: 1.6605 Acc: 0.7054\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 2.0105 Acc: 0.6284\n",
      "valid Loss: 1.6566 Acc: 0.6993\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 1.9962 Acc: 0.6303\n",
      "valid Loss: 1.6572 Acc: 0.6956\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 2.0029 Acc: 0.6284\n",
      "valid Loss: 1.6462 Acc: 0.7042\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 2.0065 Acc: 0.6386\n",
      "valid Loss: 1.6211 Acc: 0.7078\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 2.0100 Acc: 0.6281\n",
      "valid Loss: 1.6305 Acc: 0.6980\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 1.9936 Acc: 0.6339\n",
      "valid Loss: 1.6347 Acc: 0.7090\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 2.0181 Acc: 0.6235\n",
      "valid Loss: 1.6422 Acc: 0.7029\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 2.0066 Acc: 0.6340\n",
      "valid Loss: 1.6340 Acc: 0.7042\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 1.9973 Acc: 0.6372\n",
      "valid Loss: 1.6278 Acc: 0.6993\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 2.0090 Acc: 0.6328\n",
      "valid Loss: 1.6259 Acc: 0.7103\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 1.9980 Acc: 0.6328\n",
      "valid Loss: 1.6341 Acc: 0.6968\n",
      "\n",
      "Training complete in 760m 43s\n",
      "Best valid accuracy: 0.710269\n"
     ]
    }
   ],
   "source": [
    "#Trainieren des Modells\n",
    "num_epochs = 20\n",
    "if use_gpu:\n",
    "    print (\"Using GPU: \"+ str(use_gpu))\n",
    "    model = model.cuda()\n",
    "\n",
    "# \"negative log likelihood loss\" als Loss-Funktion setzen, da LogSoftmax als Aktivierungsfunktion im Output-Layer festgelegt ist wurde\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#Optimierungsfunktion (Adam-Algorythmus) und Lernrate festlegen\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0001)\n",
    "\n",
    "# Abfall der LR um den Faktor 0,1 alle 5 Epochen\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "\n",
    "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speichern des Checkpoints\n",
    "\n",
    "Nachdem das Netzwerk trainiert ist wird es abgespreichert, damit es später für Vorhersagen geladen werden kann. Zudem werden weitere Informationen wie die Anzahl der trainierten Epochen und der Optimierungsstatus (optimizer.state_dict) gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des Trainierten Netzwerkes (Checkpoint setzen)\n",
    "model.class_to_idx = dataloaders['train'].dataset.class_to_idx\n",
    "model.epochs = num_epochs\n",
    "checkpoint = {'input_size': [3, 224, 224],\n",
    "                 'batch_size': dataloaders['train'].batch_size,\n",
    "                  'output_size': 102,\n",
    "                  'state_dict': model.state_dict(),\n",
    "                  'data_transforms': data_transforms,\n",
    "                  'optimizer_dict':optimizer.state_dict(),\n",
    "                  'class_to_idx': model.class_to_idx,\n",
    "                  'epoch': model.epochs}\n",
    "torch.save(checkpoint, 'classifier270v2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
